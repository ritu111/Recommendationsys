{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip instal sentencepiece\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification,BertConfig\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import sentencepiece as spm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text  userid  \\\n",
      "0        3.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "1        5.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "2        1.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "3        4.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "4        4.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "5        3.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "6        3.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "7        4.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "8        4.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "9        4.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "10       3.0  वुडी के नेतृत्व में एंडी के खिलौने उनके कमरे म...     862   \n",
      "11       4.0  एक वयस्क जो खेल के अंदर 26 साल के लिए फंस गया ...    8844   \n",
      "12       4.5  एक वयस्क जो खेल के अंदर 26 साल के लिए फंस गया ...    8844   \n",
      "13       4.0  एक वयस्क जो खेल के अंदर 26 साल के लिए फंस गया ...    8844   \n",
      "14       4.0  एक वयस्क जो खेल के अंदर 26 साल के लिए फंस गया ...    8844   \n",
      "15       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "16       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "17       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "18       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "19       2.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "20       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "21       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "22       5.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "23       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "24       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "25       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "26       4.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "27       5.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "28       3.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "29       2.0  जुनूनी मास्टर चोर नील मक्सौली लॉस एंजिल्स भर म...     949   \n",
      "...      ...                                                ...     ...   \n",
      "19970    1.5  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19971    2.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19972    3.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19973    3.5  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19974    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19975    5.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19976    4.5  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19977    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19978    5.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19979    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19980    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19981    5.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19982    3.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19983    3.5  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19984    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19985    2.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19986    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19987    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19988    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19989    1.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19990    4.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19991    4.5  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19992    1.0  1960 के दशक में चीन में फ्रांसीसी राजनयिक रेने...    1413   \n",
      "19993    3.0  बच्चे हैं चाहते हैं जो एक खुशी से शादीशुदा जोड...    2246   \n",
      "19994    1.0  बच्चे हैं चाहते हैं जो एक खुशी से शादीशुदा जोड...    2246   \n",
      "19995    3.0  आतंकवादियों वॉशिंगटन डीसी को एक 747 भीतर का अप...    2320   \n",
      "19996    4.0  आतंकवादियों वॉशिंगटन डीसी को एक 747 भीतर का अप...    2320   \n",
      "19997    4.0  आतंकवादियों वॉशिंगटन डीसी को एक 747 भीतर का अप...    2320   \n",
      "19998    3.0  आतंकवादियों वॉशिंगटन डीसी को एक 747 भीतर का अप...    2320   \n",
      "19999    3.0  आतंकवादियों वॉशिंगटन डीसी को एक 747 भीतर का अप...    2320   \n",
      "\n",
      "                                                   genre  \n",
      "0      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "1      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "2      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "3      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "4      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "5      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "6      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "7      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "8      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "9      [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "10     [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...  \n",
      "11     [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...  \n",
      "12     [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...  \n",
      "13     [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...  \n",
      "14     [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...  \n",
      "15     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "16     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "17     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "18     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "19     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "20     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "21     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "22     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "23     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "24     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "25     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "26     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "27     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "28     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "29     [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 80...  \n",
      "...                                                  ...  \n",
      "19970  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19971  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19972  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19973  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19974  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19975  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19976  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19977  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19978  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19979  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19980  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19981  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19982  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19983  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19984  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19985  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19986  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19987  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19988  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19989  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19990  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19991  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19992  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 1...  \n",
      "19993  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 8...  \n",
      "19994  [{'आ ी डी': 18, 'नाम': 'ड्रामा'}, {'आ ी डी': 8...  \n",
      "19995  [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 12...  \n",
      "19996  [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 12...  \n",
      "19997  [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 12...  \n",
      "19998  [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 12...  \n",
      "19999  [{'आ ी डी': 28, 'नाम': 'एक्शन'}, {'आ ी डी': 12...  \n",
      "\n",
      "[20000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "1        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "2        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "3        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "4        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "5        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "6        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "7        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "8        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "9        [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "10       [वुडी, के, नेतृत्व, में, एंडी, के, खिलौने, उनक...\n",
      "11       [एक, वयस्क, जो, खेल, के, अंदर, 26, साल, के, लि...\n",
      "12       [एक, वयस्क, जो, खेल, के, अंदर, 26, साल, के, लि...\n",
      "13       [एक, वयस्क, जो, खेल, के, अंदर, 26, साल, के, लि...\n",
      "14       [एक, वयस्क, जो, खेल, के, अंदर, 26, साल, के, लि...\n",
      "15       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "16       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "17       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "18       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "19       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "20       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "21       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "22       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "23       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "24       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "25       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "26       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "27       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "28       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "29       [जुनूनी, मास्टर, चोर, नील, मक्सौली, लॉस, एंजिल...\n",
      "                               ...                        \n",
      "19970    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19971    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19972    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19973    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19974    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19975    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19976    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19977    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19978    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19979    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19980    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19981    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19982    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19983    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19984    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19985    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19986    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19987    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19988    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19989    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19990    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19991    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19992    [1960, के, दशक, में, चीन, में, फ्रांसीसी, राजन...\n",
      "19993    [बच्चे, हैं, चाहते, हैं, जो, एक, खुशी, से, शाद...\n",
      "19994    [बच्चे, हैं, चाहते, हैं, जो, एक, खुशी, से, शाद...\n",
      "19995    [आतंकवादियों, वॉशिंगटन, डीसी, को, एक, 747, भीत...\n",
      "19996    [आतंकवादियों, वॉशिंगटन, डीसी, को, एक, 747, भीत...\n",
      "19997    [आतंकवादियों, वॉशिंगटन, डीसी, को, एक, 747, भीत...\n",
      "19998    [आतंकवादियों, वॉशिंगटन, डीसी, को, एक, 747, भीत...\n",
      "19999    [आतंकवादियों, वॉशिंगटन, डीसी, को, एक, 747, भीत...\n",
      "Name: text, Length: 20000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##Fine tuning LM on movies dataset\n",
    "\n",
    "ratings = pd.read_excel(\"ratings.xlsx\", encoding='utf-8', sep='\\t', header=[0])\n",
    "data = pd.read_excel(\"10k moviemetadatahindi.xlsx\", encoding='utf-8', sep='\\t', header=[0],sheet_name='Sheet2')\n",
    "\n",
    "dataset =  pd.merge(data[['id','imdb_id','overview','genres']].copy(),ratings, how = 'inner', left_on ='id', right_on = 'movieId')\n",
    "dataset = dataset[:20000].copy()\n",
    "\n",
    "df = pd.DataFrame({'label':dataset.rating, 'text':dataset.overview,'userid':dataset.id,'genre':dataset.genres})\n",
    "df = df.reset_index(drop = True)\n",
    "# print(df)\n",
    "\n",
    "for i in range(0, 1):                                                     \n",
    "    df['text'] = df['text'].str.replace('।', '') \n",
    "    df['text'] = df['text'].str.replace(',', '') \n",
    "    df['text'] = df['text'].str.replace(\"'\", '') \n",
    "    df['text'] = df['text'].str.replace(\":\", '') \n",
    "    df['text'] = df['text'].str.replace(\"{\", '')\n",
    "    df['text'] = df['text'].str.replace(\"}\", '') \n",
    "\n",
    "    print(df)\n",
    "\n",
    "tokenized_doc = df['text'].apply(lambda k: list(k.split(\" \")))\n",
    "print(tokenized_doc)\n",
    "\n",
    "\n",
    "detokenized_doc = [] \n",
    "for i in range(len(df)): \n",
    "    t = ' '.join(tokenized_doc[i]) \n",
    "    detokenized_doc.append(t) \n",
    "\n",
    "df['text'] = detokenized_doc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.2, random_state = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HindiTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(\"hindi_lm_large.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(\"hindi_lm_large.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(30000)]  \n",
    "    \n",
    "hindi_vocab = Vocab(itos)\n",
    "tokenizer = Tokenizer(tok_func=HindiTokenizer, lang='hi')\n",
    "\n",
    "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\",tokenizer=tokenizer,vocab=hindi_vocab)\n",
    "learn = language_model_learner(data_lm, drop_mult=0.7, arch=AWD_LSTM, pretrained=False) \n",
    "##we have to make pretrained as false so that it doesn't load weights from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.254105</td>\n",
       "      <td>0.099766</td>\n",
       "      <td>0.980152</td>\n",
       "      <td>27:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.load('model')\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWD_LSTM(\n",
       "  (encoder): Embedding(30000, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(30000, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1152, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1152, 1152, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1152, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_trn['text'].values[1]))\n",
    "# print((df_trn['text'].values[1]))\n",
    "# print(tokenized_doc)\n",
    "# tokenized_doc.apply(lambda m : tokenized_word.append(m))\n",
    "# print(tokenized_word[0])\n",
    "# df_trn['text']= df['text'].apply(lambda k: list(k.split(\" \")))\n",
    "# df['text']=tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trn=df_trn.reset_index(drop =True)\n",
    "\n",
    "# a=df_trn['text']\n",
    "# print(a[5])\n",
    "# for i in range(0,len(df_trn['text'])):\n",
    "#     df_trn['text'].values[i]=learn.model[0](learn.data.one_item(a[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HindiDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "    \n",
    "        pass a dataframe with userid, label, text\n",
    "        \n",
    "        \"\"\"\n",
    "        self.n = data.shape[0]\n",
    "        self.userid =  data['userid'].tolist()\n",
    "        self.label = data['label'].tolist()\n",
    "        self.hindiSent =  data['text'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return  self.label[idx], self.hindiSent[idx], self.userid[idx]\n",
    "    \n",
    "    \n",
    "# dataset = HindiDataset(data=df)\n",
    "# dataloader = DataLoader(dataset, 64, shuffle=True, num_workers=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=HindiDataset(data=df_trn)\n",
    "train_loader = DataLoader(train_df, 64, shuffle=True, num_workers=1)  \n",
    "val_df=HindiDataset(data=df_val)\n",
    "val_loader = DataLoader(val_df, 64, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "vocab_size=1200\n",
    "embed_size = 100\n",
    "n_hidden = 128\n",
    "n_layers = 3\n",
    "batchSize=64\n",
    "output_size=11\n",
    "n_user=len(df_trn['userid'].unique())\n",
    "print(n_user)\n",
    "max_user=max(df_trn['userid'].unique())+1\n",
    "\n",
    "seq_length=150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size, n_user,embed_size,n_hidden,n_layers,output_size, batchSize\n",
    "             , batch_first=True,):\n",
    "\n",
    "        super(UserEmbedding,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_batch = batchSize\n",
    "\n",
    "        self.encoder_layer = learn.model[0]\n",
    "\n",
    "        #self.awd = AWD_LSTM(vocab_sz = 30000, emb_sz = 400, n_hid=1152, n_layers =3)\n",
    "        self.linear1 = nn.Linear(400,100)\n",
    "        #self.linear2 = nn.Sequential(self.awd, self.linear1)\n",
    "        self.linear3 = nn.Linear(400, 64)\n",
    "\n",
    "        self.embedding = nn.Embedding(max_user, embed_size)\n",
    "\n",
    "        self.linear7 = nn.Linear(200,32) \n",
    "        self.linear8 = nn.Linear(32,output_size)\n",
    "\n",
    "    def forward(self, sents, users, hidden):\n",
    "\n",
    "        b=(learn.data.one_item(sents[0]))\n",
    "        raw_outputs,outputs=self.encoder_layer(b[0])\n",
    "        lstm_out = raw_outputs[2]           \n",
    "        lstm_out_mean1 = lstm_out.mean(1)\n",
    "        \n",
    "        for i in range(1,len(sents)):\n",
    "            b=(learn.data.one_item(sents[i]))\n",
    "            raw_outputs,outputs = self.encoder_layer(b[0])\n",
    "            lstm_out = raw_outputs[2]  \n",
    "           \n",
    "            lstm_out_mean = lstm_out.mean(1)\n",
    "            lstm_out_mean1=torch.cat((lstm_out_mean1,lstm_out_mean),dim=0)\n",
    "        \n",
    "        out1 = F.relu(torch.FloatTensor(self.linear1(lstm_out_mean1)))\n",
    "\n",
    "        userEmbed = self.embedding(users)\n",
    "        out3 = torch.cat((out1, userEmbed), dim=1)\n",
    "\n",
    "        out3 = F.relu(self.linear7(out3))\n",
    "        out3 = self.linear8(out3)\n",
    "#         out3 = self.linear9(out3) \n",
    "#         print(out3,\"out3:\")\n",
    "        return out3,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "\n",
    "        weight = next(self.parameters()).data            \n",
    "        hidden = (weight.new(self.n_layers,self.n_batch,self.n_hidden).zero_(),\n",
    "                  weight.new(self.n_layers,self.n_batch,self.n_hidden).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.reset()\n",
    "model = UserEmbedding(vocab_size,n_user,embed_size,n_hidden,n_layers,output_size,batchSize,output_size)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "print(len(df_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3200625 [32.00625]\n",
      "0.3309375 [32.00625, 33.09375]\n",
      "0.329875 [32.00625, 33.09375, 32.9875]\n",
      "0.3349375 [32.00625, 33.09375, 32.9875, 33.49375]\n",
      "0.3306875 [32.00625, 33.09375, 32.9875, 33.49375, 33.06875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-561:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x126cbf6a8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/util.py\", line 325, in _exit_function\n",
      "    _run_finalizers()\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1364-b2f9e129f7c9>\", line 22, in <module>\n",
      "    lloss1.backward()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/tensor.py\", line 118, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "losses = []\n",
    "total_loss=[]\n",
    "predicted_rating=[]\n",
    "accuracy_list=[]\n",
    "for i in range(0,20):\n",
    "    correct1=0\n",
    "    \n",
    "    for label,text,userid in train_loader:\n",
    "        model.zero_grad()\n",
    "    \n",
    "        hidden =  model.init_hidden()\n",
    "        hidden = ([each.data for each in hidden])\n",
    "        output1,hidden  = model(text,userid,hidden)\n",
    "        _, predicted= torch.topk(output1,k=1)  \n",
    "        predicted=predicted.type(torch.DoubleTensor)\n",
    "        correct=predicted.data.eq(label.data.view_as(predicted.data)).sum()    ###taking sum of all corrected values for a batch\n",
    "#         print(correct)\n",
    "        correct1=correct1+correct.item()\n",
    "#         print(correct1)\n",
    "        lloss1= loss(output1, label.long())\n",
    "        lloss1.backward()\n",
    "        optimizer.step()\n",
    "#         break \n",
    "    accuracy=(correct1/len(df_trn))*100\n",
    "    accuracy_list.append(accuracy)    \n",
    "    print(correct1/len(df_trn),accuracy_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144982\n"
     ]
    }
   ],
   "source": [
    "# print(df_trn)\n",
    "max_user=max(df_trn['userid'].unique())\n",
    "print(max_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-788-c49cd1edcc68>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-788-c49cd1edcc68>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    learn.model[0](learn.data.one_item(doc)) for doc in sent:\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(tensor([[ 2963,  2906,  7891,   204, 17318,  3770,     3,   199,  1227,  7925,\n",
      "         10493,  1227,    10,   135, 17343, 24411,     9,   508,  9087,    94,\n",
      "          1550,  6561]]), tensor([0]))\n",
      "torch.Size([1, 22])\n",
      "[tensor([[[-2.2595e-02, -9.3924e-04, -4.6787e-01,  ...,  3.6226e-04,\n",
      "          -2.3961e-02,  8.4022e-02],\n",
      "         [-5.7533e-03,  4.1126e-03,  1.9538e-02,  ...,  1.0123e-01,\n",
      "          -1.3887e-01, -1.4714e-01],\n",
      "         [ 9.2288e-06,  1.4811e-03, -9.7586e-03,  ...,  8.1067e-01,\n",
      "          -9.0614e-01,  3.7632e-01],\n",
      "         ...,\n",
      "         [ 1.9264e-02,  3.7402e-01,  3.2342e-02,  ...,  9.1470e-02,\n",
      "           6.1285e-02, -1.2380e-01],\n",
      "         [ 1.0562e-03, -2.3039e-01,  1.0042e-01,  ...,  4.8998e-02,\n",
      "           1.3700e-01, -2.6615e-01],\n",
      "         [ 8.6229e-04,  1.8219e-01,  3.9752e-02,  ...,  4.8402e-03,\n",
      "           1.2127e-01, -2.1040e-01]]], grad_fn=<TransposeBackward0>), tensor([[[-0.0262,  0.0166,  0.0060,  ...,  0.0073,  0.0013, -0.0550],\n",
      "         [-0.0068,  0.0692,  0.0004,  ...,  0.1014,  0.0007, -0.0039],\n",
      "         [-0.0050,  0.0046,  0.0176,  ...,  0.0219,  0.0014, -0.0017],\n",
      "         ...,\n",
      "         [ 0.0259,  0.2151,  0.0180,  ...,  0.0017, -0.0008, -0.0709],\n",
      "         [ 0.0106,  0.1373,  0.0240,  ...,  0.0019, -0.0015, -0.0134],\n",
      "         [ 0.0029,  0.2765,  0.0330,  ...,  0.0222, -0.0020, -0.0341]]],\n",
      "       grad_fn=<TransposeBackward0>), tensor([[[ 5.5654e-03,  1.9370e-03, -2.3531e-01,  ..., -7.7732e-02,\n",
      "           3.6341e-03, -2.5688e-02],\n",
      "         [ 6.6857e-03,  2.2524e-03, -2.2453e-02,  ..., -9.7277e-03,\n",
      "          -1.0378e-02,  7.8209e-03],\n",
      "         [ 1.2413e-02, -8.7216e-04, -1.9689e-03,  ..., -6.2172e-03,\n",
      "           4.1446e-02,  2.6663e-04],\n",
      "         ...,\n",
      "         [ 3.3885e-01,  1.0150e-03,  8.7913e-01,  ..., -1.1566e-01,\n",
      "          -1.6766e-01, -5.8946e-03],\n",
      "         [-1.7015e-01, -8.9606e-02,  8.0703e-01,  ..., -6.7852e-01,\n",
      "          -5.3437e-01, -1.6856e-02],\n",
      "         [ 2.1761e-01, -4.6417e-05,  6.2135e-01,  ..., -3.3657e-01,\n",
      "           8.8204e-02, -9.2122e-02]]], grad_fn=<TransposeBackward0>)]\n",
      "torch.Size([1, 22, 400])\n"
     ]
    }
   ],
   "source": [
    "text = ('जुआ स्वर्ग के जीवन ऐ लास वेगास ऐ और उसके अंधेरे माफिया ुंडेरबेल्ली', 'जेम्स बॉन्ड जानूस सिंडीकेट की रहस्यमय सिर बेनकाब और ब्रिटेन पर')\n",
    "# learn.data.one_item(text)\n",
    "\n",
    "print(len(text))\n",
    "for i in range(0,1):\n",
    "    b = learn.data.one_item(text[i])\n",
    "    print(b)\n",
    "#     print((b[0]))\n",
    "    print(b[0].shape)\n",
    "    raw,out = learn.model[0](b[0])\n",
    "    print((raw[2].shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWD_LSTM(\n",
       "  (encoder): Embedding(30000, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(30000, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1152, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1152, 1152, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1152, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.0147,  0.0063, -0.0092,  ...,  0.0065, -0.0221, -0.0112],\n",
       "           [ 0.0133,  0.0206, -0.0111,  ...,  0.0107, -0.0292, -0.0093],\n",
       "           [ 0.0079,  0.0122, -0.0063,  ...,  0.0110, -0.0370, -0.0021],\n",
       "           ...,\n",
       "           [ 0.0018,  0.0251, -0.0063,  ...,  0.0191, -0.0279, -0.0019],\n",
       "           [ 0.0139,  0.0147,  0.0039,  ...,  0.0184, -0.0235, -0.0056],\n",
       "           [ 0.0046,  0.0101, -0.0002,  ...,  0.0078, -0.0296,  0.0008]]],\n",
       "         grad_fn=<TransposeBackward0>),\n",
       "  tensor([[[-0.0057, -0.0063, -0.0239,  ..., -0.0053, -0.0018, -0.0302],\n",
       "           [-0.0073, -0.0049, -0.0212,  ..., -0.0064, -0.0014, -0.0296],\n",
       "           [-0.0073, -0.0039, -0.0205,  ..., -0.0091, -0.0005, -0.0303],\n",
       "           ...,\n",
       "           [-0.0084, -0.0035, -0.0179,  ..., -0.0060,  0.0005, -0.0281],\n",
       "           [-0.0082, -0.0028, -0.0187,  ..., -0.0065,  0.0010, -0.0296],\n",
       "           [-0.0086, -0.0031, -0.0199,  ..., -0.0068,  0.0009, -0.0292]]],\n",
       "         grad_fn=<TransposeBackward0>),\n",
       "  tensor([[[-0.0159, -0.0022,  0.0040,  ..., -0.0131,  0.0168,  0.0216],\n",
       "           [-0.0164, -0.0027,  0.0040,  ..., -0.0120,  0.0187,  0.0211],\n",
       "           [-0.0166, -0.0026,  0.0040,  ..., -0.0115,  0.0194,  0.0205],\n",
       "           ...,\n",
       "           [-0.0183, -0.0041,  0.0031,  ..., -0.0100,  0.0210,  0.0204],\n",
       "           [-0.0182, -0.0041,  0.0036,  ..., -0.0099,  0.0212,  0.0206],\n",
       "           [-0.0180, -0.0045,  0.0040,  ..., -0.0101,  0.0212,  0.0209]]],\n",
       "         grad_fn=<TransposeBackward0>)],\n",
       " [tensor([[[ 0.0165,  0.0071, -0.0103,  ...,  0.0073, -0.0000, -0.0000],\n",
       "           [ 0.0149,  0.0230, -0.0124,  ...,  0.0119, -0.0000, -0.0000],\n",
       "           [ 0.0088,  0.0136, -0.0070,  ...,  0.0123, -0.0000, -0.0000],\n",
       "           ...,\n",
       "           [ 0.0020,  0.0280, -0.0070,  ...,  0.0214, -0.0000, -0.0000],\n",
       "           [ 0.0155,  0.0165,  0.0043,  ...,  0.0205, -0.0000, -0.0000],\n",
       "           [ 0.0051,  0.0113, -0.0002,  ...,  0.0088, -0.0000,  0.0000]]],\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[-0.0064, -0.0070, -0.0267,  ..., -0.0059, -0.0020, -0.0338],\n",
       "           [-0.0081, -0.0054, -0.0237,  ..., -0.0071, -0.0016, -0.0331],\n",
       "           [-0.0081, -0.0043, -0.0229,  ..., -0.0101, -0.0006, -0.0338],\n",
       "           ...,\n",
       "           [-0.0094, -0.0040, -0.0200,  ..., -0.0067,  0.0006, -0.0314],\n",
       "           [-0.0092, -0.0032, -0.0209,  ..., -0.0073,  0.0011, -0.0330],\n",
       "           [-0.0096, -0.0034, -0.0223,  ..., -0.0076,  0.0010, -0.0326]]],\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[[-0.0159, -0.0022,  0.0040,  ..., -0.0131,  0.0168,  0.0216],\n",
       "           [-0.0164, -0.0027,  0.0040,  ..., -0.0120,  0.0187,  0.0211],\n",
       "           [-0.0166, -0.0026,  0.0040,  ..., -0.0115,  0.0194,  0.0205],\n",
       "           ...,\n",
       "           [-0.0183, -0.0041,  0.0031,  ..., -0.0100,  0.0210,  0.0204],\n",
       "           [-0.0182, -0.0041,  0.0036,  ..., -0.0099,  0.0212,  0.0206],\n",
       "           [-0.0180, -0.0045,  0.0040,  ..., -0.0101,  0.0212,  0.0209]]],\n",
       "         grad_fn=<TransposeBackward0>)])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=learn.model[0]\n",
    "sents='abccccc'\n",
    "a(learn.data.one_item(sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([1, 3, 1152])\n",
      "torch.Size([1, 3, 1152])\n",
      "torch.Size([1, 3, 1152])\n"
     ]
    }
   ],
   "source": [
    "ennc = learn.model[0](torch.tensor([[0,1,2]]))\n",
    "print(len(ennc))\n",
    "\n",
    "print((ennc[0][0].shape))\n",
    "print((ennc[1][0].shape))\n",
    "print((ennc[0][1].shape))\n",
    "\n",
    "\n",
    "a='the'\n",
    "# learn.model[0]\n",
    "# print(learn.model[0](learn.data.one_item(a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x116947d30>, <matplotlib.lines.Line2D object at 0x116626908>, <matplotlib.lines.Line2D object at 0x116947e80>, <matplotlib.lines.Line2D object at 0x116955400>]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "param_range=np.arange(0,10,1)\n",
    "accuracy_list=31.918750000000003, 33.63125, 34.20625, 33.8375, 33.75625, 33.775, 33.93125, 33.9125, 33.56875, 34.46875\n",
    "accuracy_list1=28.2369, 31.406250000000004, 33.39375, 33.775, 33.99375, 34.14375, 33.95625, 33.75, 33.918749999999996, 32.69\n",
    "accuracy_list2=25.24500084, 31.406250000000004, 32.39375, 32.775, 32.99375, 32.14375, 32.95625, 31.75,32.29, 31.8\n",
    "accuracy_list3=25.106250000000003, 31.406250000000004, 33.39375, 33.775, 33.99375, 34.14375, 33.95625, 33.75, 33.918749999999996, 34.050000000000004\n",
    "w=plt.plot(param_range, accuracy_list, label=\"0.001 Adam\", color=\"green\")\n",
    "x=plt.plot(param_range,accuracy_list1, label=\"0.01 Adam\", color=\"black\")\n",
    "y=plt.plot(param_range,accuracy_list2, label=\"0.001 SGD\", color=\"grey\")\n",
    "z=plt.plot(param_range,accuracy_list3, label=\"0.01 SGD\", color=\"blue\")\n",
    "plt.legend()\n",
    "print(w+x+y+z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
