{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from pytorch_pretrained_bert import BertForSequenceClassification,BertConfig\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp  mov_avg_rating\n",
      "0       1      110     1.0  1425941529        4.025251\n",
      "1       1      147     4.5  1425942435        3.462500\n",
      "2       1      858     5.0  1425941523        4.333763\n",
      "3       1     1221     5.0  1425941546        4.274766\n",
      "4       1     1246     5.0  1425941556        3.911153\n",
      "   adult  belongs_to_collection    budget  \\\n",
      "0  False                    NaN  30000000   \n",
      "1  False                    NaN  65000000   \n",
      "2  False                    NaN         0   \n",
      "3  False                    NaN  16000000   \n",
      "4  False                    NaN         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...   \n",
      "1  [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...   \n",
      "2  [{'आ ी डी': 10749, 'नाम': 'रोमांस'}, {'आ ी डी'...   \n",
      "3  [{'आ ी डी': 35, 'नाम': 'कॉमेडी'}, {'आ ी डी': 1...   \n",
      "4                  [{'आ ी डी': 35, 'नाम': 'कॉमेडी'}]   \n",
      "\n",
      "                                            genres.1     id    imdb_id  \\\n",
      "0  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    862  tt0114709   \n",
      "1  [{'आ ी डी': 12, 'नाम': 'एडवेंचर'}, {'आ ी डी': ...   8844  tt0113497   \n",
      "2  [{'आ ी डी': 10749, 'नाम': 'रोमांस'}, {'आ ी डी'...  15602  tt0113228   \n",
      "3  [{'आ ी डी': 35, 'नाम': 'कॉमेडी'}, {'आ ी डी': 1...  31357  tt0114885   \n",
      "4                  [{'आ ी डी': 35, 'नाम': 'कॉमेडी'}]  11862  tt0113041   \n",
      "\n",
      "  original_language             original_title  \\\n",
      "0                en                 टॉय िसटोरी   \n",
      "1                en                   जुमान्जी   \n",
      "2                en          गरुमपिएर ओल्ड में   \n",
      "3                en         वेटिंग तो एक्सहेले   \n",
      "4                en  फादर ऑफ़ थे ब्राइड पार्ट ी   \n",
      "\n",
      "                                            overview    ...      \\\n",
      "0  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...    ...       \n",
      "1  एक वयस्क जो खेल के अंदर 26 साल के लिए फंस गया ...    ...       \n",
      "2  एक परिवार शादी अगले दरवाजे पड़ोसियों और मछली प...    ...       \n",
      "3  साथ धोखा, दुर्व्यवहार और पर कदम रखा, महिलाओं क...    ...       \n",
      "4  बस जब जॉर्ज बैंकों अपनी बेटी की शादी से बरामद ...    ...       \n",
      "\n",
      "          release_date    revenue  runtime  \\\n",
      "0             30/10/95  373554033     81.0   \n",
      "1             15/12/95  262797249    104.0   \n",
      "2             22/12/95          0    101.0   \n",
      "3             22/12/95   81452156    127.0   \n",
      "4  1995-10-02 00:00:00   76578911    106.0   \n",
      "\n",
      "                                    spoken_languages status  \\\n",
      "0           [{'iso_639_1': 'en', 'name': 'English'}]   रिहा   \n",
      "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...    NaN   \n",
      "2           [{'iso_639_1': 'en', 'name': 'English'}]    NaN   \n",
      "3           [{'iso_639_1': 'en', 'name': 'English'}]    NaN   \n",
      "4           [{'iso_639_1': 'en', 'name': 'English'}]    NaN   \n",
      "\n",
      "                                             tagline  title video  \\\n",
      "0                                            #VALUE!    NaN   NaN   \n",
      "1                       पासा रोल और उत्तेजना दिलाने!    NaN   NaN   \n",
      "2  अब भी चिल्ला रहा है। अब भी लड़ रहे हैं। फिर भी...    NaN   NaN   \n",
      "3  मित्र लोग हैं, जो आप अपने आप को रहने दो ... और...    NaN   NaN   \n",
      "4  बस जब उनकी दुनिया वापस सामान्य है ... वह अपने ...    NaN   NaN   \n",
      "\n",
      "  vote_average vote_count  \n",
      "0          7.7        NaN  \n",
      "1          6.9        NaN  \n",
      "2          6.5        NaN  \n",
      "3          6.1        NaN  \n",
      "4          5.7        NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "# MODEL = 'bert-base-multilingual-uncased'\n",
    "\n",
    "ratings = pd.read_excel(\"ratings.xlsx\", encoding='utf-8', sep='\\t', header=[0])\n",
    "data = pd.read_excel(\"10k moviemetadatahindi.xlsx\", encoding='utf-8', sep='\\t', header=[0],sheet_name='Sheet2')\n",
    "#data.head()\n",
    "print(ratings.head())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mov_avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...</td>\n",
       "      <td>[{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>862</td>\n",
       "      <td>3.0</td>\n",
       "      <td>858335006</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...</td>\n",
       "      <td>[{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...</td>\n",
       "      <td>2103</td>\n",
       "      <td>862</td>\n",
       "      <td>5.0</td>\n",
       "      <td>946044912</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...</td>\n",
       "      <td>[{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...</td>\n",
       "      <td>5380</td>\n",
       "      <td>862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878941641</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...</td>\n",
       "      <td>[{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...</td>\n",
       "      <td>6177</td>\n",
       "      <td>862</td>\n",
       "      <td>4.0</td>\n",
       "      <td>859415226</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...</td>\n",
       "      <td>[{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...</td>\n",
       "      <td>6525</td>\n",
       "      <td>862</td>\n",
       "      <td>4.0</td>\n",
       "      <td>857388995</td>\n",
       "      <td>3.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    imdb_id                                           overview  \\\n",
       "0  862  tt0114709  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...   \n",
       "1  862  tt0114709  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...   \n",
       "2  862  tt0114709  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...   \n",
       "3  862  tt0114709  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...   \n",
       "4  862  tt0114709  वुडी के नेतृत्व में, एंडी के खिलौने उनके कमरे ...   \n",
       "\n",
       "                                              genres  userId  movieId  rating  \\\n",
       "0  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    1923      862     3.0   \n",
       "1  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    2103      862     5.0   \n",
       "2  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    5380      862     1.0   \n",
       "3  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    6177      862     4.0   \n",
       "4  [{'आ ी डी': 16, 'नाम': 'एनीमेशन'}, {'आ ी डी': ...    6525      862     4.0   \n",
       "\n",
       "   timestamp  mov_avg_rating  \n",
       "0  858335006        3.454545  \n",
       "1  946044912        3.454545  \n",
       "2  878941641        3.454545  \n",
       "3  859415226        3.454545  \n",
       "4  857388995        3.454545  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset =  pd.merge(data[['id','imdb_id','overview','genres']].copy(),ratings, how = 'inner', left_on ='id', right_on = 'movieId')\n",
    "#dataset = dataset[:50000].copy()\n",
    "#print(len(dataset))\n",
    "#Counter(dataset['rating'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Preprocessing of moviedata\n",
    "stoi = {}\n",
    "itos = {}\n",
    "text_corpus = []\n",
    "dictionary = []\n",
    "indexed_number = []\n",
    "tokenized_word = []\n",
    "segment_masks = []\n",
    "labels = dataset['rating']\n",
    "\n",
    "minx, maxx = 10000, 0\n",
    "batchSize = 64\n",
    "totalSize =  len(dataset) \n",
    "dataSize= len(dataset)\n",
    "# dataSize = int(totalSize / batchSize) * batchSize\n",
    "# print(dataSize)\n",
    "\n",
    "for i in range(0, 1):                                                     ## Replacing full stop with nothing ##\n",
    "    dataset['overview'] = dataset['overview']+dataset['genres']\n",
    "    dataset['overview'] = dataset['overview'].str.replace('।', '') \n",
    "    dataset['overview'] = dataset['overview'].str.replace(',', '') \n",
    "    dataset['overview'] = dataset['overview'].str.replace(\"'\", '') \n",
    "    dataset['overview'] = dataset['overview'].str.replace(\":\", '') \n",
    "    dataset['overview'] = dataset['overview'].str.replace(\"{\", '')\n",
    "    dataset['overview'] = dataset['overview'].str.replace(\"}\", '') \n",
    "\n",
    "#for i in range(0, dataSize): \n",
    "##         dataset['overview'].values[i] = dataset['overview'].values[i] + (dataset['genres'].values[i])\n",
    "##         dataset['overview'].values[i] = \"[CLS] \"+ str(dataset['overview'].values[i])+ str(dataset['genres'].values[i]) +\" [SEP]\" \n",
    "#        dataset['overview'].values[i] = \"[CLS] \"+ str(dataset['overview'].values[i]) +\" [SEP]\"\n",
    "##         dataset['overview'].values[i] = tokenizer.tokenize(dataset['overview'].values[i])\n",
    "#        dataset['overview'].values[i] = (dataset['overview'].values[i]).split(\" \")\n",
    "## \n",
    "#        tokenized_text = dataset['overview'].values[i]\n",
    "##         print(tokenized_text)\n",
    "##         stoi = {e:i for i,e in enumerate(tokenized_text)}\n",
    "##         indexed_tokens = stoi(tokenized_text)\n",
    "##         print(indexed_tokens)\n",
    "##         for a in zip(tokenized_text, indexed_tokens):\n",
    "##             stoi.update({a[0]: a[1]})\n",
    "##             itos.update({a[1]: a[0]})\n",
    "#            \n",
    "##         text_corpus.append([stoi[tok] for tok in tokenized_text]) \n",
    "##         print(text_corpus)\n",
    "#        tokenized_word=tokenized_word+tokenized_text\n",
    "#    \n",
    "#        if  i % 10000 == 0 :\n",
    "#            print(i)\n",
    "##         tokenized_word.append(tokenized_text)\n",
    "##         all_space_tokens=all_space_tokens.append(all_space_tokens)\n",
    "## print(tokenized_word)\n",
    "## print(len(stoi))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['overview'] = dataset[['overview',].values[i] + (dataset['genres'].values[i])\n",
    "dataset['overview'] =  dataset['overview'].apply(lambda k : list(k.split(\" \")))\n",
    "tokenized_text = dataset['overview'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "5         None\n",
       "6         None\n",
       "7         None\n",
       "8         None\n",
       "9         None\n",
       "10        None\n",
       "11        None\n",
       "12        None\n",
       "13        None\n",
       "14        None\n",
       "15        None\n",
       "16        None\n",
       "17        None\n",
       "18        None\n",
       "19        None\n",
       "20        None\n",
       "21        None\n",
       "22        None\n",
       "23        None\n",
       "24        None\n",
       "25        None\n",
       "26        None\n",
       "27        None\n",
       "28        None\n",
       "29        None\n",
       "          ... \n",
       "303073    None\n",
       "303074    None\n",
       "303075    None\n",
       "303076    None\n",
       "303077    None\n",
       "303078    None\n",
       "303079    None\n",
       "303080    None\n",
       "303081    None\n",
       "303082    None\n",
       "303083    None\n",
       "303084    None\n",
       "303085    None\n",
       "303086    None\n",
       "303087    None\n",
       "303088    None\n",
       "303089    None\n",
       "303090    None\n",
       "303091    None\n",
       "303092    None\n",
       "303093    None\n",
       "303094    None\n",
       "303095    None\n",
       "303096    None\n",
       "303097    None\n",
       "303098    None\n",
       "303099    None\n",
       "303100    None\n",
       "303101    None\n",
       "303102    None\n",
       "Name: overview, Length: 303103, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['overview'].apply(lambda m : tokenized_word.append(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "# pickle.dump(tokenized_word, \"tokenized_word.bin\")\n",
    "\n",
    "#with open(\"binary_list.bin\",\"wb\") as f:\n",
    "#    pickle.dump(tokenized_word, f)\n",
    "#    \n",
    "with open(\"binary_list.bin\",\"rb\") as f:\n",
    "    tokenized_word = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "बस जब जॉर्ज बैंकों अपनी बेटी की शादी से बरामद किया गया है, वह खबर यह है कि वह गर्भवती है प्राप्त करता है ... और जॉर्ज की पत्नी नीना भी उम्मीद कर रही है कि। उन्होंने कहा कि उनके घर की बिक्री पर योजना बना रहा था, लेकिन यह एक योजना है कि है - जॉर्ज की तरह - दोनों एक पोता और अपनी खुद की एक बच्चा के आगमन के साथ बदलने के लिए होगा।\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#\n",
    "#dataset[\"overview\"]=[\"\".join(overview) for overview in dataset[\"overview\"].values]\n",
    "##print(dataset[\"overview\"])\n",
    "#\n",
    "#vectorizer=TfidfVectorizer()\n",
    "#response= vectorizer.fit_transform(dataset[\"overview\"])\n",
    "## print(response)\n",
    "#list(vectorizer.vocabulary_.keys())[:100]\n",
    "## print(vectorizer.get_feature_names())\n",
    "print(data['overview'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((tokenized_word))\n",
    "my_list=[]\n",
    "train_stoi = {e:i for i,e in enumerate(tokenized_word[:260000])}\n",
    "\n",
    "my_list=[]\n",
    "test_stoi = {e:i for i,e in enumerate(tokenized_word[260000:])}\n",
    "\n",
    "#print(stoi)\n",
    "\n",
    "# def CountFrequency(my_list): \n",
    "      \n",
    "#     # Creating an empty dictionary  \n",
    "#     freq = {} \n",
    "#     for items in my_list: \n",
    "#         freq[items] = my_list.count(items) \n",
    "      \n",
    "#     for key, value in freq.items(): \n",
    "#         print (\"% d : % d\"%(key, value))\n",
    "# print(CountFrequency(tokenized_word))        \n",
    "        \n",
    "\n",
    "# print(stoi)\n",
    "# print(len(stoi))\n",
    "#k = Counter(tokenized_word) \n",
    "#print(k.most_common(102))\n",
    "# Counter(stoi.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जुनूनी', 'मास्टर', 'चोर', 'नील', 'मक्सौली', 'लॉस', 'एंजिल्स', 'भर', 'में', 'विभिन्न', 'पागल', 'चोरियों', 'पर', 'एक', 'शीर्ष', 'पायदान', 'चालक', 'दल', 'की', 'ओर', 'जाता', 'है', 'जबकि', 'एक', 'मानसिक', 'रूप', 'से', 'अस्थिर', 'जासूस', 'विंसेंट', 'हैना', 'आराम', 'के', 'बिना', 'उसे', 'कर्मों', 'प्रत्येक', 'मनुष्य', 'को', 'पहचानता', 'है', 'और', 'क्षमता', 'और', 'अन्य', 'के', 'समर्पण', 'भले', 'ही', 'वे', 'जागरूक', 'अपनी', 'बिल्ली', 'और', 'चूहे', 'खेल', 'हिंसा', 'में', 'खत्म', 'हो', 'सकता', 'है', 'कर', 'रहे', 'हैं', 'सम्मान', 'करता', 'है[आ', 'ी', 'डी', '28', 'नाम', 'एक्शन', 'आ', 'ी', 'डी', '80', 'नाम', 'क्राइम', 'आ', 'ी', 'डी', '18', 'नाम', 'ड्रामा', 'आ', 'ी', 'डी', '53', 'नाम', 'थ्रिलर]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_word[20])\n",
    "stoi = {e:i for elist in tokenized_word  for i,e in enumerate(elist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max count : 229\n",
      "Min Count : 1\n",
      "[[ 0  0  0 ... 59 50 33]\n",
      " [ 0  0  0 ... 59 50 33]\n",
      " [ 0  0  0 ... 59 50 33]\n",
      " ...\n",
      " [ 0  0  0 ... 43 50 27]\n",
      " [ 0  0  0 ... 43 50 27]\n",
      " [ 0  0  0 ... 50 51 52]]\n",
      "303103\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, dataSize): \n",
    "        text_corpus.append([stoi[tok] for tok in tokenized_text[i]]) \n",
    "#         print(text_corpus)\n",
    "        tokenized_word.append(tokenized_text)\n",
    "    \n",
    "\n",
    "for i in range(0, dataSize):\n",
    "    if len(dataset['overview'].values[i]) < minx: minx = len(dataset['overview'].values[i])\n",
    "    if len(dataset['overview'].values[i]) > maxx: maxx = len(dataset['overview'].values[i])\n",
    "\n",
    "print(\"Max count :\",maxx)\n",
    "print(\"Min Count :\",minx)        \n",
    "        \n",
    "def pad_sequence(corpus, max_length):                                                ## Adding padding\n",
    "    feature = np.zeros((len(corpus), max_length), dtype=int)\n",
    "    for i, row in enumerate(corpus):\n",
    "        feature[i][-len(row):] = np.array(row)[:max_length]\n",
    "    return feature\n",
    "\n",
    "corpus = pad_sequence(text_corpus, maxx)\n",
    "print(corpus)\n",
    "print(len(corpus))\n",
    "\n",
    "\n",
    "y_map = {e:i for i,e in enumerate(set(data['vote_average']))}\n",
    "print(len(y_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272792 30311\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1)\n",
    "print(len(train),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max count : 229\n",
      "Min Count : 1\n",
      "[[ 0  0  0 ... 59 50 33]\n",
      " [ 0  0  0 ... 59 50 33]\n",
      " [ 0  0  0 ... 59 50 33]\n",
      " ...\n",
      " [ 0  0  0 ... 43 50 27]\n",
      " [ 0  0  0 ... 43 50 27]\n",
      " [ 0  0  0 ... 50 51 52]]\n",
      "303103\n",
      "81\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[int(item)] += 1      \n",
    "        \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    \n",
    "    weight = [0] * len(images)                                              \n",
    "    \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[int(val)]                                  \n",
    "    \n",
    "    return weight  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272768\n",
      "272768\n",
      "272768\n",
      "0          1923\n",
      "1          2103\n",
      "2          5380\n",
      "3          6177\n",
      "4          6525\n",
      "5          7050\n",
      "6          7238\n",
      "7          8659\n",
      "8          9328\n",
      "9          9682\n",
      "10        10425\n",
      "11         7016\n",
      "12         7144\n",
      "13         8659\n",
      "14         9547\n",
      "15          174\n",
      "16          346\n",
      "17          362\n",
      "18          384\n",
      "19          463\n",
      "20          523\n",
      "21          557\n",
      "22          609\n",
      "23          624\n",
      "24          773\n",
      "25          825\n",
      "26          959\n",
      "27         1107\n",
      "28         1149\n",
      "29         1608\n",
      "          ...  \n",
      "272738    10071\n",
      "272739    10082\n",
      "272740    10083\n",
      "272741    10111\n",
      "272742    10114\n",
      "272743    10128\n",
      "272744    10132\n",
      "272745    10141\n",
      "272746    10150\n",
      "272747    10165\n",
      "272748    10168\n",
      "272749    10169\n",
      "272750    10191\n",
      "272751    10215\n",
      "272752    10223\n",
      "272753    10250\n",
      "272754    10253\n",
      "272755    10259\n",
      "272756    10268\n",
      "272757    10296\n",
      "272758    10312\n",
      "272759    10322\n",
      "272760    10329\n",
      "272761    10335\n",
      "272762    10336\n",
      "272763    10339\n",
      "272764    10346\n",
      "272765    10357\n",
      "272766    10370\n",
      "272767    10389\n",
      "Name: userId, Length: 272768, dtype: int64\n",
      "30272\n",
      "30272\n",
      "30272\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x13d51ae10>\n"
     ]
    }
   ],
   "source": [
    "##TRAIN\n",
    "batchSize = 64\n",
    "embed_size=100\n",
    "\n",
    "totalSize =  len(train)\n",
    "dataSize = int(totalSize / batchSize) * batchSize\n",
    "# print(dataSize)\n",
    "\n",
    "train_dataset=dataset[0:dataSize]\n",
    "n_user=len(train_dataset['userId'].unique())\n",
    "train_input=train_dataset['userId']\n",
    "out_rating = (train_dataset['rating'][0:len(train_input)])\n",
    "out_rating=out_rating*2\n",
    "out_rating[0]=0\n",
    "# print(output2)\n",
    "output_size = len(out_rating.unique())\n",
    "train_corpus=corpus[0:len(train_input)]\n",
    "print(len(train_input))\n",
    "print(len(train_corpus))\n",
    "print(len(out_rating))\n",
    "print(train_input)\n",
    "\n",
    "##TEST\n",
    "\n",
    "test_size = len(test)\n",
    "test_size = int(test_size/batchSize) * batchSize\n",
    "# print(test_size)\n",
    "# print((dataSize2))\n",
    "# print(len(corpus))\n",
    "test_data=dataset[dataSize:dataSize+test_size]\n",
    "test_input = test_data['userId']\n",
    "test_output = test_data['rating']\n",
    "test_output=test_output*2\n",
    "# test_output[0]=0\n",
    "test_corpus=corpus[dataSize:dataSize+test_size]\n",
    "print(len(test_input))\n",
    "print(len(test_output))\n",
    "print(len(test_corpus))\n",
    "\n",
    "weights =  make_weights_for_balanced_classes(out_rating.values,11)\n",
    "weights = torch.DoubleTensor(weights)                                       \n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))                     \n",
    "                                                                                \n",
    "#train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, shuffle = True,                              \n",
    "#                                                             sampler = sampler, num_workers=args.workers, pin_memory=True)     \n",
    "\n",
    "\n",
    "\n",
    "dset = TensorDataset(torch.from_numpy(np.array(train_input)),torch.from_numpy(np.array(train_corpus)), torch.from_numpy(np.array(out_rating)))\n",
    "\n",
    "train_loader = DataLoader(dset,sampler=sampler, batch_size=batchSize)\n",
    "\n",
    "tset= TensorDataset(torch.from_numpy(np.array(test_input)),torch.from_numpy(np.array(test_corpus)), torch.from_numpy(np.array(test_output)))\n",
    "test_loader = DataLoader(tset,  shuffle = False, batch_size=batchSize)\n",
    "# print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3.0: 71039,\n",
       "         5.0: 49355,\n",
       "         1.0: 10472,\n",
       "         4.0: 83197,\n",
       "         4.5: 19997,\n",
       "         2.0: 21673,\n",
       "         3.5: 28633,\n",
       "         2.5: 11834,\n",
       "         0.5: 3394,\n",
       "         1.5: 3509})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13750\n",
      "229\n"
     ]
    }
   ],
   "source": [
    "### Variables initialization\n",
    "vocab_size = len(stoi)\n",
    "print(len(stoi))\n",
    "embed_size1 = 100\n",
    "n_hidden = 128\n",
    "n_layers = 3\n",
    "seq_length = maxx\n",
    "print(seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10231\n",
      "272768\n",
      "[ 0. 10.  2.  8.  6.  9.  4.  7.  5.  1.  3.]\n",
      "11\n",
      "10656\n"
     ]
    }
   ],
   "source": [
    "print(n_user)\n",
    "print(len(train_input))\n",
    "# print(output.unique())\n",
    "print((out_rating.unique()))\n",
    "print(output_size)\n",
    "print(max(dataset['userId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size, n_user,embed_size, n_hidden,n_layers,output_size, batchSize\n",
    "                 ,seq_length, lstm_dropout=0.2 , batch_first=True,):\n",
    "        \n",
    "        super(UserEmbedding,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_batch = batchSize\n",
    "        \n",
    "        self.movieembedding=nn.Embedding(24523000,embed_size)\n",
    "        self.lstm_net =  nn.LSTM(embed_size,n_hidden,n_layers,dropout =0.5 , batch_first = batch_first)\n",
    "        self.linear1 = nn.Linear(seq_length  * n_hidden , 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "               \n",
    "        self.embedding = nn.Embedding(24523000, embed_size)\n",
    "        self.linear4 = nn.Linear(embed_size , 256)\n",
    "        self.linear5 = nn.Linear(256, 128)\n",
    "        self.linear6 = nn.Linear(128, 64)\n",
    "\n",
    "        self.linear7 = nn.Linear(64+64,32) \n",
    "        self.linear8 = nn.Linear(32,output_size)\n",
    "#         self.linear9 = nn.Linear(16, output_size)\n",
    "               \n",
    "    def forward(self, sents, users, hidden):\n",
    "        sentEmbed = self.embedding(sents)\n",
    "        lstm_out, hidden =  self.lstm_net(sentEmbed,hidden)\n",
    "        lstm_out =  lstm_out.contiguous().view(self.n_batch,-1)  ## Changing size, reshape\n",
    "        out1 = F.relu(self.linear1(lstm_out))\n",
    "        out1 = F.relu(self.linear2(out1))\n",
    "        out1 = F.relu(self.linear3(out1))\n",
    "        \n",
    "        userEmbed = self.embedding(users)\n",
    "        out2 = F.relu(self.linear4(userEmbed))\n",
    "        out2 = F.relu(self.linear5(out2))\n",
    "        out2 = F.relu(self.linear6(out2))\n",
    "        \n",
    "        out3 = torch.cat((out1, out2), dim=1)\n",
    "        out3 = F.relu(self.linear7(out3))\n",
    "        out3 = self.linear8(out3)\n",
    "#         out3 = self.linear9(out3)\n",
    "              \n",
    "        return out3,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \n",
    "        weight = next(self.parameters()).data            \n",
    "        hidden = (weight.new(self.n_layers,self.n_batch,self.n_hidden).zero_(),\n",
    "                  weight.new(self.n_layers,self.n_batch,self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  UserEmbedding(vocab_size,n_user,embed_size,n_hidden,n_layers,output_size,batchSize, seq_length,output_size)\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "losses = []\n",
    "total_loss=[]\n",
    "predicted_rating=[]\n",
    "accuracy_list=[]\n",
    "for i in range(0,40):\n",
    "    correct1=0\n",
    "    \n",
    "    for users,sentence, ratings in train_loader:\n",
    "        model.zero_grad()\n",
    "    \n",
    "        hidden =  model.init_hidden()\n",
    "        hidden = ([each.data for each in hidden])\n",
    "        output1,hidden  = model(sentence,users,hidden)\n",
    "        _, predicted= torch.topk(output1,k=1)  \n",
    "        predicted=predicted.type(torch.DoubleTensor)\n",
    "        correct=predicted.data.eq(ratings.data.view_as(predicted.data)).sum()    ###taking sum of all corrected values for a batch\n",
    "\n",
    "        correct1=correct1+correct.item()\n",
    "        lloss1= loss(output1, ratings.long())\n",
    "        lloss1.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    accuracy=(correct1/len(train_input))*100\n",
    "    accuracy_list.append(accuracy)    \n",
    "    print(correct1/len(train_input),accuracy_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "losses = []\n",
    "total_loss=[]\n",
    "predicted_rating=[]\n",
    "accuracy_list=[]\n",
    "for i in range(0,1):\n",
    "    correct1=0\n",
    "    \n",
    "    for users,sentence, ratings in test_loader:\n",
    "        model.zero_grad()\n",
    "        hidden =  model.init_hidden()\n",
    "        hidden = ([each.data for each in hidden])\n",
    "        output1,hidden  = model(sentence,users,hidden)\n",
    "        _, predicted= torch.topk(output1,k=1)  #returns topk values, indexes\n",
    "        predicted=predicted.type(torch.DoubleTensor)\n",
    "        correct=predicted.data.eq(ratings.data.view_as(predicted.data)).sum()    ###taking sum of all corrected values for a batch\n",
    "\n",
    "        correct1=correct1+correct.item()\n",
    "        lloss1= loss(output1, ratings.long())\n",
    "\n",
    "    accuracy=(correct1/len(test_input))*100\n",
    "    accuracy_list.append(accuracy)    \n",
    "    print(correct1/len(test_input),accuracy_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
